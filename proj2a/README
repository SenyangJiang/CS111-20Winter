NAME: Senyang Jiang
EMAIL: senyangjiang@yahoo.com
ID: 505111806

INCLUDED FILES:
lab2_add.c ... a C program that implements and tests a shared variable add function and produces the specified output statistics.
SortedList.h ... a header file describing the interfaces for linked list operations
SortedList.c ... a C module that implements insert, delete, lookup, and length methods for a sorted doubly linked list
lab2_list.c ... a C program that implements shared list operation and produces the specified output statistics.
Makefile ... Supports five targets
	 build ... (default target) compile all programs (with the -Wall and -Wextra options).
	 tests ... run all (over 200) specified test cases to generate results in CSV files.
	 graphs ... use gnuplot and the supplied data reduction scripts to generate the required graphs
	 dist ... create the deliverable tarball
	 clean ... delete all programs and output created by the Makefile
lab2_add.csv ... containing all of the results for all of the Part-1 tests
lab2_list.csv ... containing all of the results for all of the Part-2 tests
lab2_add-1.png ... threads and iterations required to generate a failure (with and without yields)
lab2_add-2.png ... average time per operation with and without yields.
lab2_add-3.png ... average time per (single threaded) operation vs. the number of iterations.
lab2_add-4.png ... threads and iterations that can run successfully with yields under each of the synchronization options.
lab2_add-5.png ... average time per (protected) operation vs. the number of threads.
lab2_list-1.png ... average time per (single threaded) unprotected operation vs. number of iterations (illustrating the correction of the per-operation cost for the list length).
lab2_list-2.png ... threads and iterations required to generate a failure (with and without yields).
lab2_list-3.png ... iterations that can run (protected) without failure.
lab2_list-4.png ... (length-adjusted) cost per operation vs the number of threads for the various synchronization options.
lab2_add.gp ... Data reduction scripts for data from add
lab2_list.gp ... Data reduction scripts for data from list

QUESTION 2.1.1 - causing conflicts:
1. Why does it take many iterations before errors are seen?
Since creating threads is expensive, if the number of iteration is small, the thread created would finish before the next thread is created. So the number of iterations has to be large for race condition to arise.

2. Why does a significantly smaller number of iterations so seldom fail?
Same reason. If the number of iteration is small, it is very likely that the thread created would finish before the next thread is created. So it seldom fail.

QUESTION 2.1.2 - cost of yielding:
1. Why are the --yield runs so much slower? Where is the additional time going?
Because --yield option forces the thread to yield when it is about to update the new value. Since the thread yields before its time slice expires, extra time would be spent switching between threads(changing program counter, stack, stack pointer, etc). Context switch would cost a lot of time.

2. Is it possible to get valid per-operation timings if we are using the --yield option? If so, explain how. If not, explain why not.
It is not possible to get valid per-operation timing in this case because the time spent on yielding and switching threads is added to the total time, and we are not sure how much time was spent on context switch.

QUESTION 2.1.3 - measurement errors:
1. Why does the average cost per operation drop with increasing iterations?
As the num of iterations increases, the start-up cost of creating threads is amortized, so the average cost per operation drops.

2. If the cost per iteration is a function of the number of iterations, how do we know how many iterations to run (or what the "correct" cost is)?
As the number of iterations gets sufficiently large, the cost per iteration would converge to a certain value, since the start-up cost becomes negligible compare to the total cost. In other words, when the function becomes flat, we know the true cost per operation.

QUESTION 2.1.4 - costs of serialization:
1. Why do all of the options perform similarly for low numbers of threads?
When the number of thread is low, not much time is wasted on those threads that are not able to get the lock. As a result, for low number of threads the program performs similarly with or without threads.

2. Why do the three protected operations slow down as the number of threads rises?
Only one thread can move through the critical section at a certain time. As the number of threads rises, the proportion of time wasted on threads waiting for the lock gets larger and hence the three protected operations slow down.

QUESTION 2.2.1 - scalability of Mutex
1. Comment on the general shapes of the curves, and explain why they have this shape.
In part 1 and part 2, the curve increases. As the number of threads increases, the cost of context switch also rises, which explains why cost per operation increases.

2. Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.
The rate of increase in part 2 is higher than the rate of increase in part 1. This is because list operation is more complex than the adding operation, which means that more locks and unlocks are involved in list operation. So as the number of threads increases, the overhead in part 2 is greater, and the cost per operation increases faster.

QUESTION 2.2.2 - scalability of spin locks
1. Comment on the general shapes of the curves, and explain why they have this shape.
As the numeber of threads increases, cost per operation for both spin locks and mutex increases, since the overhead of context switch is larger.

2. Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.
The rate of increase for Spin lock is higher. As the number of threads increases, for Spin lock much more time was spent on wasteful spinning, but for mutex the waiting threads would sleep and does not consume CPU cycles.